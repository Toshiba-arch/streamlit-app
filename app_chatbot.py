import streamlit as st
from openai import OpenAI
import openai
import time

# Fun√ß√£o para inicializar o cliente OpenAI
def initialize_openai_client():
    openai_api_key = st.secrets.get("openai_api_key")
    if not openai_api_key:
        st.error("API Key n√£o configurada. Por favor, adicione-a em **Settings > Secrets**.", icon="üõë")
        return None
    return OpenAI(api_key=openai_api_key)

# Fun√ß√£o para exibir o t√≠tulo da aplica√ß√£o
def show_app_title():
    st.title("üí¨ Chatbot com GPT e Mais Funcionalidades")
    st.write("Este √© um chatbot simples alimentado pelo modelo GPT-4. Al√©m disso, voc√™ pode gerar imagens, transcrever √°udio, gerar √°udio a partir de texto e muito mais!")

# Fun√ß√£o para exibir a descri√ß√£o de cada funcionalidade
def show_feature_description(feature):
    descriptions = {
        "Chatbot Padr√£o": "O chatbot permite que voc√™ converse com um modelo GPT para obter respostas inteligentes sobre diversos temas.",
        "Chatbot com Racioc√≠nio": "Este chatbot utiliza um modelo avan√ßado da OpenAI com habilidades de racioc√≠nio para resolver problemas mais complexos e oferecer solu√ß√µes detalhadas.",
        "An√°lise de Imagens": "Voc√™ pode carregar uma URL de imagem para an√°lise do conte√∫do presente nela.",
        "Gerar Haiku": "Crie haikus personalizados sobre temas espec√≠ficos com a ajuda da IA.",
        "Texto para Imagem": "Voc√™ pode gerar imagens a partir de descri√ß√µes de texto, utilizando a API de imagens da OpenAI.",
        "√Åudio para Texto": "Essa funcionalidade converte arquivos de √°udio em texto, usando a API da OpenAI.",
        "Texto para Fala": "Gere √°udio falado a partir de texto, criando falas realistas com a OpenAI.",
        "Fala para Texto": "Converta √°udio gravado ou ao vivo para texto, √∫til para transcri√ß√µes de conversa.",
        "Embeddings": "Crie embeddings para comparar textos semanticamente, √∫til para buscas e recomenda√ß√µes baseadas em conte√∫do."
    }
    st.expander(f"üîç Sobre {feature}", expanded=True).markdown(descriptions.get(feature, "Sem descri√ß√£o dispon√≠vel"))

# Fun√ß√£o para exibir o Chatbot Padr√£o
def show_chatbot(client):
    st.write("### üí¨ Chatbot com GPT")
    if "messages" not in st.session_state:
        st.session_state.messages = []
        
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    prompt = st.chat_input("Digite sua mensagem:")
    if prompt:
        if len(prompt) > 500:
            st.warning("Sua mensagem √© muito longa. Por favor, seja mais breve!")
        else:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
            )
            response = completion.choices[0].message.content
            with st.chat_message("assistant"):
                st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})

    # Bot√µes de limpar hist√≥rico e baixar hist√≥rico
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("üßπ Limpar hist√≥rico"):
            st.session_state.messages = []
            st.info("Hist√≥rico de mensagens limpo!")
    with col2:
        if st.download_button(
            "üíæ Baixar hist√≥rico do chat",
            data="\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.messages]),
            file_name="chat_history.txt",
            mime="text/plain"
        ):
            st.success("Hist√≥rico baixado com sucesso!")

# Fun√ß√£o para exibir o Chatbot com Racioc√≠nio
def show_reasoning_chatbot(client):
    st.write("### üí¨ Chatbot com Racioc√≠nio (GPT-4 com Reasoning)")
    if "reasoning_messages" not in st.session_state:
        st.session_state.reasoning_messages = []
        
    for message in st.session_state.reasoning_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    prompt = st.chat_input("Digite sua mensagem para racioc√≠nio:")
    if prompt:
        if len(prompt) > 500:
            st.warning("Sua mensagem √© muito longa. Por favor, seja mais breve!")
        else:
            st.session_state.reasoning_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Usar o modelo com racioc√≠nio (Reasoning)
            reasoning_prompt = f"Para resolver este problema, siga um racioc√≠nio passo a passo: {prompt}"
            completion = client.chat.completions.create(
                model="gpt-4",  # Usando modelo com racioc√≠nio avan√ßado
                messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.reasoning_messages]
            )
            response = completion.choices[0].message.content
            with st.chat_message("assistant"):
                st.markdown(response)
            st.session_state.reasoning_messages.append({"role": "assistant", "content": response})

    # Bot√µes de limpar hist√≥rico e baixar hist√≥rico
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("üßπ Limpar hist√≥rico"):
            st.session_state.reasoning_messages = []
            st.info("Hist√≥rico de mensagens limpo!")
    with col2:
        if st.download_button(
            "üíæ Baixar hist√≥rico do chat",
            data="\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.reasoning_messages]),
            file_name="reasoning_chat_history.txt",
            mime="text/plain"
        ):
            st.success("Hist√≥rico baixado com sucesso!")

# Fun√ß√£o para exibir a An√°lise de Imagens
def show_image_analysis(client):
    st.write("### An√°lise de Imagens com GPT")
    image_url = st.text_input("Insira a URL da imagem para an√°lise:")
    if image_url:
        st.image(image_url, caption="Imagem carregada")
        # Chamada para a API para analisar a imagem (exemplo fict√≠cio)
        st.write("Aqui voc√™ pode adicionar a l√≥gica para analisar a imagem.")

# Fun√ß√£o para exibir o Gerador de Haiku
def show_haiku_generation(client):
    st.write("### Gerador de Haiku")
    haiku_theme = st.text_input("Tema do Haiku (opcional):", placeholder="Por exemplo: tecnologia, natureza, etc.")
    if st.button("üìú Gerar Haiku"):
        haiku_prompt = f"Escreva um haiku sobre {haiku_theme}" if haiku_theme else "Escreva um haiku sobre IA"
        haiku_completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": haiku_prompt}]
        )
        haiku = haiku_completion.choices[0].message.content
        st.markdown(f"**Haiku:**\n\n{haiku}")

# Fun√ß√£o para gerar imagem a partir de texto
def show_text_to_image(client):
    st.write("### Gerar Imagem a partir de Texto")
    text_prompt = st.text_input("Digite a descri√ß√£o da imagem desejada:")
    if text_prompt:
        response = client.images.create(prompt=text_prompt, n=1, size="1024x1024")
        image_url = response['data'][0]['url']
        st.image(image_url, caption="Imagem gerada pela IA")

# Fun√ß√£o para converter √°udio em texto
def show_audio_to_text(client):
    st.write("### Converter √Åudio em Texto")
    audio_file = st.file_uploader("Envie um arquivo de √°udio (MP3, WAV, etc.):", type=["mp3", "wav"])
    if audio_file:
        st.audio(audio_file, format='audio/wav')
        st.write("Convertendo √°udio para texto...")
        # Substituir pelo c√≥digo real para transcri√ß√£o, se necess√°rio.
        transcript = "Texto transcrito do √°udio (exemplo)."
        st.write("Transcri√ß√£o:", transcript)

# Fun√ß√£o para gerar fala a partir de texto
def show_text_to_speech(client):
    st.write("### Gerar Fala a partir de Texto")
    text_input = st.text_input("Digite o texto para gerar a fala:")
    if text_input:
        # Gerar √°udio de fala com a API de texto para fala
        st.audio("audio_output.mp3", format="audio/mp3")  # Exemplo fict√≠cio de √°udio

# Fun√ß√£o para converter fala em texto
def show_speech_to_text(client):
    st.write("### Converter Fala em Texto")
    audio_file = st.file_uploader("Envie um arquivo de √°udio para transcri√ß√£o:", type=["mp3", "wav"])
    if audio_file:
        st.audio(audio_file, format="audio/wav")
        st.write("Convertendo fala para texto...")
        # Aqui a API de transcri√ß√£o de fala seria chamada.
        transcribed_text = "Texto transcrito da fala."
        st.write("Texto transcrito:", transcribed_text)

# Fun√ß√£o para gerar embeddings de texto
def show_embeddings(client):
    st.write("### Gerar Embeddings de Texto")
    input_text = st.text_area("Digite o texto para gerar o embedding:")
    if input_text:
        embeddings = client.embeddings.create(input=[input_text])
        st.write("Embeddings gerados:", embeddings['data'][0]['embedding'])

# Fun√ß√£o principal para exibir a interface
def run():
    show_app_title()
    
    # Inicializa√ß√£o do cliente OpenAI
    client = initialize_openai_client()
    if not client:
        return  # Se a API key n√£o estiver configurada, interrompe a execu√ß√£o

    # Menu de funcionalidades
    feature = st.selectbox(
        "Escolha a funcionalidade:",
        ("Chatbot Padr√£o", "Chatbot com Racioc√≠nio", "An√°lise de Imagens", "Gerar Haiku", "Texto para Imagem", "√Åudio para Texto", "Texto para Fala", "Fala para Texto", "Embeddings")
    )
    
    # Exibir a descri√ß√£o
    show_feature_description(feature)

    # Exibir a funcionalidade selecionada
    if feature == "Chatbot Padr√£o":
        show_chatbot(client)
    elif feature == "Chatbot com Racioc√≠nio":
        show_reasoning_chatbot(client)
    elif feature == "An√°lise de Imagens":
        show_image_analysis(client)
    elif feature == "Gerar Haiku":
        show_haiku_generation(client)
    elif feature == "Texto para Imagem":
        show_text_to_image(client)
    elif feature == "√Åudio para Texto":
        show_audio_to_text(client)
    elif feature == "Texto para Fala":
        show_text_to_speech(client)
    elif feature == "Fala para Texto":
        show_speech_to_text(client)
    elif feature == "Embeddings":
        show_embeddings(client)

# Rodar a aplica√ß√£o
if __name__ == "__main__":
    run()
