import streamlit as st
from openai import OpenAI
import openai
import time

# Funﾃｧﾃ｣o para inicializar o cliente OpenAI
def initialize_openai_client():
    openai_api_key = st.secrets.get("openai_api_key")
    if not openai_api_key:
        st.error("API Key nﾃ｣o configurada. Por favor, adicione-a em **Settings > Secrets**.", icon="泝")
        return None
    return OpenAI(api_key=openai_api_key)

# Funﾃｧﾃ｣o para exibir o tﾃｭtulo da aplicaﾃｧﾃ｣o
def show_app_title():
    st.title("汳ｬ Chatbot com GPT e Mais Funcionalidades")
    st.write("Este ﾃｩ um chatbot simples alimentado pelo modelo GPT-4. Alﾃｩm disso, vocﾃｪ pode gerar imagens, transcrever ﾃ｡udio, gerar ﾃ｡udio a partir de texto e muito mais!")

# Funﾃｧﾃ｣o para exibir a descriﾃｧﾃ｣o de cada funcionalidade
def show_feature_description(feature):
    descriptions = {
        "Chatbot Padrﾃ｣o": "O chatbot permite que vocﾃｪ converse com um modelo GPT para obter respostas inteligentes sobre diversos temas.",
        "Chatbot com Raciocﾃｭnio": "Este chatbot utiliza um modelo avanﾃｧado da OpenAI com habilidades de raciocﾃｭnio para resolver problemas mais complexos e oferecer soluﾃｧﾃｵes detalhadas.",
        "Anﾃ｡lise de Imagens": "Vocﾃｪ pode carregar uma URL de imagem para anﾃ｡lise do conteﾃｺdo presente nela.",
        "Gerar Haiku": "Crie haikus personalizados sobre temas especﾃｭficos com a ajuda da IA.",
        "Texto para Imagem": "Vocﾃｪ pode gerar imagens a partir de descriﾃｧﾃｵes de texto, utilizando a API de imagens da OpenAI.",
        "ﾃ「dio para Texto": "Essa funcionalidade converte arquivos de ﾃ｡udio em texto, usando a API da OpenAI.",
        "Texto para Fala": "Gere ﾃ｡udio falado a partir de texto, criando falas realistas com a OpenAI.",
        "Fala para Texto": "Converta ﾃ｡udio gravado ou ao vivo para texto, ﾃｺtil para transcriﾃｧﾃｵes de conversa.",
        "Embeddings": "Crie embeddings para comparar textos semanticamente, ﾃｺtil para buscas e recomendaﾃｧﾃｵes baseadas em conteﾃｺdo."
    }
    st.expander(f"沐 Sobre {feature}", expanded=True).markdown(descriptions.get(feature, "Sem descriﾃｧﾃ｣o disponﾃｭvel"))

# Funﾃｧﾃ｣o para exibir o Chatbot Padrﾃ｣o
def show_chatbot(client):
    st.write("### 汳ｬ Chatbot com GPT")
    if "messages" not in st.session_state:
        st.session_state.messages = []
        
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    prompt = st.chat_input("Digite sua mensagem:")
    if prompt:
        if len(prompt) > 500:
            st.warning("Sua mensagem ﾃｩ muito longa. Por favor, seja mais breve!")
        else:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
            )
            response = completion.choices[0].message.content
            with st.chat_message("assistant"):
                st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})

    # Botﾃｵes de limpar histﾃｳrico e baixar histﾃｳrico
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("洫ｹ Limpar histﾃｳrico"):
            st.session_state.messages = []
            st.info("Histﾃｳrico de mensagens limpo!")
    with col2:
        if st.download_button(
            "汳ｾ Baixar histﾃｳrico do chat",
            data="\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.messages]),
            file_name="chat_history.txt",
            mime="text/plain"
        ):
            st.success("Histﾃｳrico baixado com sucesso!")

# Funﾃｧﾃ｣o para exibir o Chatbot com Raciocﾃｭnio
def show_reasoning_chatbot(client):
    st.write("### 汳ｬ Chatbot com Raciocﾃｭnio (GPT-4 com Reasoning)")
    if "reasoning_messages" not in st.session_state:
        st.session_state.reasoning_messages = []
        
    for message in st.session_state.reasoning_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    prompt = st.chat_input("Digite sua mensagem para raciocﾃｭnio:")
    if prompt:
        if len(prompt) > 500:
            st.warning("Sua mensagem ﾃｩ muito longa. Por favor, seja mais breve!")
        else:
            st.session_state.reasoning_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Usar o modelo com raciocﾃｭnio (Reasoning)
            reasoning_prompt = f"Para resolver este problema, siga um raciocﾃｭnio passo a passo: {prompt}"
            completion = client.chat.completions.create(
                model="gpt-4",  # Usando modelo com raciocﾃｭnio avanﾃｧado
                messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.reasoning_messages]
            )
            response = completion.choices[0].message.content
            with st.chat_message("assistant"):
                st.markdown(response)
            st.session_state.reasoning_messages.append({"role": "assistant", "content": response})

    # Botﾃｵes de limpar histﾃｳrico e baixar histﾃｳrico
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("洫ｹ Limpar histﾃｳrico"):
            st.session_state.reasoning_messages = []
            st.info("Histﾃｳrico de mensagens limpo!")
    with col2:
        if st.download_button(
            "汳ｾ Baixar histﾃｳrico do chat",
            data="\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.reasoning_messages]),
            file_name="reasoning_chat_history.txt",
            mime="text/plain"
        ):
            st.success("Histﾃｳrico baixado com sucesso!")

# Funﾃｧﾃ｣o para exibir a Anﾃ｡lise de Imagens
def show_image_analysis(client):
    st.write("### Anﾃ｡lise de Imagens com GPT")
    image_url = st.text_input("Insira a URL da imagem para anﾃ｡lise:")
    if image_url:
        st.image(image_url, caption="Imagem carregada")
        # Chamada para a API para analisar a imagem (exemplo fictﾃｭcio)
        st.write("Aqui vocﾃｪ pode adicionar a lﾃｳgica para analisar a imagem.")

# Funﾃｧﾃ｣o para exibir o Gerador de Haiku
def show_haiku_generation(client):
    st.write("### Gerador de Haiku")
    haiku_theme = st.text_input("Tema do Haiku (opcional):", placeholder="Por exemplo: tecnologia, natureza, etc.")
    if st.button("沒 Gerar Haiku"):
        haiku_prompt = f"Escreva um haiku sobre {haiku_theme}" if haiku_theme else "Escreva um haiku sobre IA"
        haiku_completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": haiku_prompt}]
        )
        haiku = haiku_completion.choices[0].message.content
        st.markdown(f"**Haiku:**\n\n{haiku}")

# Funﾃｧﾃ｣o para gerar imagem a partir de texto
def show_text_to_image(client):
    st.write("### Gerar Imagem a partir de Texto")
    text_prompt = st.text_input("Digite a descriﾃｧﾃ｣o da imagem desejada:")
    if text_prompt:
        response = client.images.create(prompt=text_prompt, n=1, size="1024x1024")
        image_url = response['data'][0]['url']
        st.image(image_url, caption="Imagem gerada pela IA")

# Funﾃｧﾃ｣o para converter ﾃ｡udio em texto
def show_audio_to_text(client):
    st.write("### Converter ﾃ「dio em Texto")
    audio_file = st.file_uploader("Envie um arquivo de ﾃ｡udio (MP3, WAV, etc.):", type=["mp3", "wav"])
    if audio_file:
        st.audio(audio_file, format='audio/wav')
        st.write("Convertendo ﾃ｡udio para texto...")
        # Substituir pelo cﾃｳdigo real para transcriﾃｧﾃ｣o, se necessﾃ｡rio.
        transcript = "Texto transcrito do ﾃ｡udio (exemplo)."
        st.write("Transcriﾃｧﾃ｣o:", transcript)

# Funﾃｧﾃ｣o para gerar fala a partir de texto
def show_text_to_speech(client):
    st.write("### Gerar Fala a partir de Texto")
    text_input = st.text_input("Digite o texto para gerar a fala:")
    if text_input:
        # Gerar ﾃ｡udio de fala com a API de texto para fala
        st.audio("audio_output.mp3", format="audio/mp3")  # Exemplo fictﾃｭcio de ﾃ｡udio

# Funﾃｧﾃ｣o para converter fala em texto
def show_speech_to_text(client):
    st.write("### Converter Fala em Texto")
    audio_file = st.file_uploader("Envie um arquivo de ﾃ｡udio para transcriﾃｧﾃ｣o:", type=["mp3", "wav"])
    if audio_file:
        st.audio(audio_file, format="audio/wav")
        st.write("Convertendo fala para texto...")
        # Aqui a API de transcriﾃｧﾃ｣o de fala seria chamada.
        transcribed_text = "Texto transcrito da fala."
        st.write("Texto transcrito:", transcribed_text)

# Funﾃｧﾃ｣o para gerar embeddings de texto
def show_embeddings(client):
    st.write("### Gerar Embeddings de Texto")
    input_text = st.text_area("Digite o texto para gerar o embedding:")
    if input_text:
        embeddings = client.embeddings.create(input=[input_text])
        st.write("Embeddings gerados:", embeddings['data'][0]['embedding'])

# Funﾃｧﾃ｣o principal para exibir a interface
def run():
    show_app_title()
    
    # Inicializaﾃｧﾃ｣o do cliente OpenAI
    client = initialize_openai_client()
    if not client:
        return  # Se a API key nﾃ｣o estiver configurada, interrompe a execuﾃｧﾃ｣o

    # Menu de funcionalidades
    feature = st.selectbox(
        "Escolha a funcionalidade:",
        ("Chatbot Padrﾃ｣o", "Chatbot com Raciocﾃｭnio", "Anﾃ｡lise de Imagens", "Gerar Haiku", "Texto para Imagem", "ﾃ「dio para Texto", "Texto para Fala", "Fala para Texto", "Embeddings")
    )
    
    # Exibir a descriﾃｧﾃ｣o
    show_feature_description(feature)

    # Exibir a funcionalidade selecionada
    if feature == "Chatbot Padrﾃ｣o":
        show_chatbot(client)
    elif feature == "Chatbot com Raciocﾃｭnio":
        show_reasoning_chatbot(client)
    elif feature == "Anﾃ｡lise de Imagens":
        show_image_analysis(client)
    elif feature == "Gerar Haiku":
        show_haiku_generation(client)
    elif feature == "Texto para Imagem":
        show_text_to_image(client)
    elif feature == "ﾃ「dio para Texto":
        show_audio_to_text(client)
    elif feature == "Texto para Fala":
        show_text_to_speech(client)
    elif feature == "Fala para Texto":
        show_speech_to_text(client)
    elif feature == "Embeddings":
        show_embeddings(client)

# Rodar a aplicaﾃｧﾃ｣o
if __name__ == "__main__":
    run()
